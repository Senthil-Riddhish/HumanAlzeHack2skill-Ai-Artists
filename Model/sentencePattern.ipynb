{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CT8-qIGS37WD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/americanExpress/fixed_train.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X = data['prompt'] + \" \" + data['utterance']\n",
        "y = data['label']\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')"
      ],
      "metadata": {
        "id": "z_N8B6Sh4q02"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OU3-5b_d4qx_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(len(word_index) + 1, 100, input_length=max_sequence_length),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KVK0ayah41yH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDoFyDhq41wH",
        "outputId": "9341f8e6-b3aa-4d73-e928-a0c16487de14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2105/2105 - 586s - loss: -2.0083e+05 - accuracy: 0.0270 - val_loss: -5.6747e+05 - val_accuracy: 0.0269 - 586s/epoch - 278ms/step\n",
            "Epoch 2/10\n",
            "2105/2105 - 559s - loss: -1.2013e+06 - accuracy: 0.0270 - val_loss: -1.9318e+06 - val_accuracy: 0.0269 - 559s/epoch - 265ms/step\n",
            "Epoch 3/10\n",
            "2105/2105 - 547s - loss: -2.8805e+06 - accuracy: 0.0270 - val_loss: -3.8934e+06 - val_accuracy: 0.0269 - 547s/epoch - 260ms/step\n",
            "Epoch 4/10\n",
            "2105/2105 - 565s - loss: -5.1328e+06 - accuracy: 0.0270 - val_loss: -6.4093e+06 - val_accuracy: 0.0269 - 565s/epoch - 269ms/step\n",
            "Epoch 5/10\n",
            "2105/2105 - 548s - loss: -7.9305e+06 - accuracy: 0.0270 - val_loss: -9.4574e+06 - val_accuracy: 0.0269 - 548s/epoch - 260ms/step\n",
            "Epoch 6/10\n",
            "2105/2105 - 562s - loss: -1.1263e+07 - accuracy: 0.0270 - val_loss: -1.3038e+07 - val_accuracy: 0.0269 - 562s/epoch - 267ms/step\n",
            "Epoch 7/10\n",
            "2105/2105 - 558s - loss: -1.5125e+07 - accuracy: 0.0270 - val_loss: -1.7137e+07 - val_accuracy: 0.0269 - 558s/epoch - 265ms/step\n",
            "Epoch 8/10\n",
            "2105/2105 - 555s - loss: -1.9508e+07 - accuracy: 0.0270 - val_loss: -2.1757e+07 - val_accuracy: 0.0269 - 555s/epoch - 264ms/step\n",
            "Epoch 9/10\n",
            "2105/2105 - 552s - loss: -2.4412e+07 - accuracy: 0.0270 - val_loss: -2.6894e+07 - val_accuracy: 0.0269 - 552s/epoch - 262ms/step\n",
            "Epoch 10/10\n",
            "2105/2105 - 556s - loss: -2.9839e+07 - accuracy: 0.0270 - val_loss: -3.2549e+07 - val_accuracy: 0.0269 - 556s/epoch - 264ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRZ8aqrh41to",
        "outputId": "65c2d922-368e-4693-db5d-07eecd951dd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.026909824460744858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_g05sBS441q-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}